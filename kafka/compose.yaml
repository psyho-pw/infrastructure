services:
  kafka:
    image: confluentinc/cp-kafka:${KAFKA_VERSION:?required}
    hostname: kafka
    container_name: kafka
    expose:
      - "9092"
      - "9093"
      - "29092"
    environment:
      KAFKA_NODE_ID: ${KAFKA_NODE_ID:?required}
      KAFKA_PROCESS_ROLES: ${KAFKA_PROCESS_ROLES:?required}

      # Listener 설정 - SASL_PLAINTEXT (TLS는 Traefik에서 처리)
      KAFKA_LISTENERS: SASL_PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://${DOMAIN:?required}:9092,INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT,INTERNAL:SASL_PLAINTEXT

      # Controller 설정
      KAFKA_CONTROLLER_QUORUM_VOTERS: ${KAFKA_CONTROLLER_QUORUM_VOTERS:?required}
      KAFKA_CONTROLLER_LISTENER_NAMES: ${KAFKA_CONTROLLER_LISTENER_NAMES:?required}
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # SASL 설정
      KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-512
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-512
      KAFKA_SASL_MECHANISM_CONTROLLER_PROTOCOL: PLAIN

      # SASL JAAS 설정
      KAFKA_LISTENER_NAME_SASL__PLAINTEXT_SCRAM__SHA__512_SASL_JAAS_CONFIG: |
        org.apache.kafka.common.security.scram.ScramLoginModule required
        username="${KAFKA_ADMIN_USER:?required}"
        password="${KAFKA_ADMIN_PASSWORD:?required}";
      KAFKA_LISTENER_NAME_INTERNAL_SCRAM__SHA__512_SASL_JAAS_CONFIG: |
        org.apache.kafka.common.security.scram.ScramLoginModule required
        username="${KAFKA_ADMIN_USER}"
        password="${KAFKA_ADMIN_PASSWORD}";

      # 슈퍼유저 설정
      KAFKA_SUPER_USERS: "User:${KAFKA_ADMIN_USER}"

      # ACL 설정
      KAFKA_AUTHORIZER_CLASS_NAME: org.apache.kafka.metadata.authorizer.StandardAuthorizer
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "false"

      # Replication 설정
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:?required}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR:?required}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR:?required}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: ${KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS:?required}

      # Topic 설정
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_AUTO_CREATE_TOPICS_ENABLE:?required}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS:?required}
      KAFKA_DEFAULT_REPLICATION_FACTOR: ${KAFKA_DEFAULT_REPLICATION_FACTOR:?required}

      # Log 설정
      KAFKA_LOG_RETENTION_HOURS: ${KAFKA_LOG_RETENTION_HOURS:?required}
      KAFKA_LOG_SEGMENT_BYTES: ${KAFKA_LOG_SEGMENT_BYTES:?required}
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: ${KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS:?required}
      KAFKA_LOG_DIRS: ${KAFKA_LOG_DIRS:?required}

      CLUSTER_ID: ${CLUSTER_ID:?required}
    volumes:
      - ./data/kafka:/var/lib/kafka/data
    networks:
      - kafka-network
      - proxy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    labels:
      # Traefik TCP 라우팅 (Kafka)
      - "traefik.enable=true"
      - "traefik.tcp.routers.kafka.rule=HostSNI(`*`)"
      - "traefik.tcp.routers.kafka.entrypoints=kafka"
      - "traefik.tcp.routers.kafka.tls=true"
      - "traefik.tcp.services.kafka.loadbalancer.server.port=9092"

  kafka-init:
    image: confluentinc/cp-kafka:${KAFKA_VERSION}
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_ADMIN_USER: ${KAFKA_ADMIN_USER}
      KAFKA_ADMIN_PASSWORD: ${KAFKA_ADMIN_PASSWORD}
      KAFKA_CLIENT_USER: ${KAFKA_CLIENT_USER:?required}
      KAFKA_CLIENT_PASSWORD: ${KAFKA_CLIENT_PASSWORD:?required}
    volumes:
      - ./scripts/init-kafka-users.sh:/scripts/init-kafka-users.sh:ro
    entrypoint: ["/bin/bash", "/scripts/init-kafka-users.sh"]
    networks:
      - kafka-network

  kafka-ui:
    image: provectuslabs/kafka-ui:${KAFKA_UI_VERSION:?required}
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    expose:
      - "8080"
    environment:
      # Kafka 클러스터 설정
      KAFKA_CLUSTERS_0_NAME: ${KAFKA_CLUSTER_NAME:?required}
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: SCRAM-SHA-512
      KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_ADMIN_USER}\" password=\"${KAFKA_ADMIN_PASSWORD}\";"

      # Kafka UI 인증 설정
      AUTH_TYPE: ${KAFKA_UI_AUTH_TYPE:?required}
      SPRING_SECURITY_USER_NAME: ${KAFKA_UI_ADMIN_USER:?required}
      SPRING_SECURITY_USER_PASSWORD: ${KAFKA_UI_ADMIN_PASSWORD:?required}

      DYNAMIC_CONFIG_ENABLED: ${KAFKA_UI_DYNAMIC_CONFIG_ENABLED:?required}

      # Base Path 설정 (경로 기반 라우팅용)
      SERVER_SERVLET_CONTEXT_PATH: /kafka
    networks:
      - kafka-network
      - proxy
    restart: unless-stopped
    labels:
      - "traefik.enable=true"

      # HTTP 라우터 (리다이렉트용)
      - "traefik.http.routers.kafka-ui-http.rule=Host(`${DOMAIN:?required}`) && PathPrefix(`/kafka`)"
      - "traefik.http.routers.kafka-ui-http.entrypoints=web"
      - "traefik.http.routers.kafka-ui-http.middlewares=redirect-to-https@docker"

      # HTTPS 라우터 (메인)
      - "traefik.http.routers.kafka-ui.rule=Host(`${DOMAIN:?required}`) && PathPrefix(`/kafka`)"
      - "traefik.http.routers.kafka-ui.entrypoints=websecure"
      - "traefik.http.routers.kafka-ui.tls.certresolver=letsencrypt"
      - "traefik.http.services.kafka-ui.loadbalancer.server.port=8080"

networks:
  kafka-network:
    driver: bridge
  proxy:
    external: true
